\documentclass[../tfg.tex]{subfiles}

\begin{document}
\section{Introduction}
Software has bugs. This whole text depends on it. But finding bugs may not be as trivial as it seems. Software can be complex, and remembering all the corner cases for all the lines of code, taking into account how they interact with each other, is an illusion. By human mistake or lack of knowledge, programmers can introduce bugs in their software, sometimes very hard to reproduce or with very particular triggers.\\


\textbf{Fuzzing} means to use automatically generated tests to perform software testing\cite{fuzzingbook2019:index}. Fuzzing searches exhaustively on the input space (bruteforce) of a program, searching for faulty inputs that may cause misbehavior by the software. This technique has been very successful on finding security bugs on software in the last decade and has gained a lot of popularity. It is in fact, a critical component of software testing even for production environments.

\section{Code coverage}
It is a metric which measures how much of the program has been executed. This metric helps to know how complete a test has been. By using code coverage we can quantify the usefulness of the input cases generated by the fuzzer and optimize the fuzzing session.
Coverage can be defined on different criteria:
\begin{itemize}
  \item Functions executed.
  \item Statements executed.
  \item Edges taken.
  \item Branches taken.
  \item Conditions resolved.
\end{itemize}

\section{Types of fuzzers}
Fuzzers are typically classified in 3 dimensions.
\subsection{Input seed}
\subsubsection{Generative}
The fuzzer generates the input from scratch, usually by random methods. This technique has as advantages the ease of implementation, does not require a \emph{corpus} of examples and can generate a broad spectrum of input cases, but present the disadvantage of generating a lot of uninteresting inputs . Because of its triviality only uncovers shallow bugs in non trivial programs and takes a lot of time and effort to generate input cases that go down in the program execution tree.

\subsubsection{Mutations}
The most part of randomly generated inputs are not syntactically valid and do not go further on a program path. Mutation-based fuzzers apply certain transformations (mutations) to already existing examples of input to produce new input, thus they require a \emph{corpus}. These mutations usually retain the structure of the input, if there is one. Because of the similarity between the generated input and the \emph{corpus} examples the fuzzer can focus on interesting cases that go deep in the program execution tree, but it is not as exhaustive as the generative method.
Some common mutations include:
\begin{itemize}

  \item Bitflips
  \item Arithmetic
  \item Removing/Adding bytes
  \item Swapping bytes
  \item Repeating bytes
  \item Inserting UTF characters into ASCII strings
  \item Removing/Adding new lines, null terminators, EOFs, ...
  \item Replacing numbers for known problematic ones, i.e. negatives, big integers, floats, ...

\end{itemize}

\subsection{Input structure}
\subsubsection{Unstructured}
The fuzzer does not know the structure of the input. Requires less setup for fuzzing and can be employed in a wide variety of programs. This technique is more exhaustive than structured data but can generate a lot of uninteresting input cases for programs that expect structured data, which means wasting CPU cycles. It also takes longer to explore the program execution tree.

\subsubsection{Structured}
The format of the input is specified to the fuzzer. Then the fuzzer can generate new inputs from this specification. It is specially useful for fuzzing highly structured data like protocols, file formats or sequences of mouse clicks or keyboard events, etcetera. The goal of structured input is to reduce the number of trivial inputs that are going to be rejected quickly by the target program, achieving a deeper exploration of the program execution tree than unstructured input.
Generally, the input format is specified as a formal grammar.

\subsection{Program knowledge}
\subsubsection{Blackbox}
The fuzzer is not allowed to scan or analyze the internals parts of the program. The executable is treated as a black box that receives input and prints output. The fuzzer generates inputs for the target program without knowledge of its internal behavior or implementation.
Because this technique does not modify the source code, nor injects instrumentation and does not analyze test coverage after each execution, there are no overheads at runtime, making it suitable for large or slow binaries. It does not need access to the source code.

\subsubsection{Whitebox}
The fuzzer is allowed to analyze the whole program. The goal is to track and maximize code coverage. This is done by adding \emph{instrumentation} to the original source code and required compilation. This instrumentation is just a logger that registers when a checkpoint is reached along the execution path of a program. Target checkpoints are usually function prologues and epilogues, jumps and conditional statements.

Thanks to all this structural analysis of the program the fuzzer can triage inputs depending on how much code coverage they contribute, if new paths have been discovered, or which types of input flow through one path or another. This makes this technique the most effective at finding deep hidden bugs. The downside is the overhead of the instrumentation and that for every execution, the output feedback must be analyzed by the fuzzer to continue generating input, plus one does not always have access to the source code or cannot compile the program.

\subsubsection{Greybox}
Greybox fuzzing tries to maintain the benefits of whitebox fuzzing while minimizing its downsides. It also uses instrumentation, but much lighter, instrumenting certain files or instructions and without analyzing the whole program. This technique is the most popular of the three as the top big 3 fuzzers AFL, HongFuzz and LibFuzzer use the greybox technique.

\end{document}
